{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0e03f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding images 8000â€“9000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [1:08:59<00:00,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: (1000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "\n",
    "# Load meta\n",
    "with open(r\"D:\\food_recommender\\embeddings\\meta_clean_original_paths.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "# Embed the NEXT 1000 images AFTER index 8000 â†’ indices 8000 to 9000\n",
    "start_idx = 8000\n",
    "end_idx = start_idx + 1000  # 9000\n",
    "\n",
    "image_paths = meta[\"image_path\"][start_idx:end_idx]\n",
    "\n",
    "image_embeds = []\n",
    "\n",
    "for img_path in tqdm(image_paths, desc=f\"Embedding images {start_idx}â€“{end_idx}\"):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb = model.get_image_features(**inputs)\n",
    "\n",
    "    emb = emb / emb.norm(dim=-1, keepdim=True)\n",
    "    image_embeds.append(emb.cpu().numpy())\n",
    "\n",
    "image_embeds = np.vstack(image_embeds).astype(\"float32\")\n",
    "\n",
    "np.save(r\"D:\\food_recommender\\embeddings\\image_embeds_8000_to_9000.npy\", image_embeds)\n",
    "\n",
    "print(\"DONE:\", image_embeds.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c25b97b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index size: 1000\n",
      "Saved FAISS index â†’ faiss_image.index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "# ============================\n",
    "#  Load embeddings + meta\n",
    "# ============================\n",
    "EMB_PATH = r\"D:\\food_recommender\\embeddings\\image_embeds_8000_to_9000.npy\"\n",
    "\n",
    "# ============================\n",
    "#  Create FAISS index\n",
    "# ============================\n",
    "embeds = np.load(EMB_PATH).astype(\"float32\")\n",
    "d = embeds.shape[1]   # embedding dimension\n",
    "index = faiss.IndexFlatL2(d)  # L2 cosine-normalized = works well\n",
    "\n",
    "index.add(embeds)  # add all embeddings\n",
    "print(\"FAISS index size:\", index.ntotal)\n",
    "\n",
    "# ============================\n",
    "#  Save index\n",
    "# ============================\n",
    "faiss.write_index(index, r\"D:/food_recommender/embeddings/faiss_image_index_cleaned_8000_to_9000.bin\")\n",
    "print(\"Saved FAISS index â†’ faiss_image.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "818d9af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base index: D:\\food_recommender\\embeddings\\faiss_image_index_cleaned.bin (500 vectors)\n",
      "Appended 1500 vectors from D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_500_to_2000.bin\n",
      "Appended 2000 vectors from D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_2000_to_4000.bin\n",
      "Appended 1000 vectors from D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_4000_to_5000.bin\n",
      "Appended 3000 vectors from D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_5000_to_7999.bin\n",
      "Appended 1000 vectors from D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_8000_to_9000.bin\n",
      "Appended 4471 vectors from D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_9000_to_end.bin\n",
      "=================================\n",
      "âœ… Final index size: 13471\n",
      "ðŸ’¾ Saved combined index â†’ D:\\food_recommender\\embeddings\\faiss_all_images.bin\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ============================\n",
    "#  CONFIG\n",
    "# ============================\n",
    "INDEX_FILES = [\n",
    "    r\"D:\\food_recommender\\embeddings\\faiss_image_index_cleaned.bin\",\n",
    "    r\"D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_500_to_2000.bin\",\n",
    "    r\"D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_2000_to_4000.bin\",\n",
    "    r\"D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_4000_to_5000.bin\",\n",
    "    r\"D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_5000_to_7999.bin\",\n",
    "    r\"D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_8000_to_9000.bin\",\n",
    "    r\"D:\\food_recommender\\embeddings\\faiss_image_index_cleaned_9000_to_end.bin\"\n",
    "]\n",
    "\n",
    "OUT_INDEX = r\"D:\\food_recommender\\embeddings\\faiss_all_images.bin\"\n",
    "\n",
    "# ============================\n",
    "#  LOAD BASE INDEX\n",
    "# ============================\n",
    "base_index = faiss.read_index(INDEX_FILES[0])\n",
    "d = base_index.d\n",
    "\n",
    "print(f\"Loaded base index: {INDEX_FILES[0]} ({base_index.ntotal} vectors)\")\n",
    "\n",
    "# ============================\n",
    "#  APPEND OTHERS\n",
    "# ============================\n",
    "for path in INDEX_FILES[1:]:\n",
    "    assert os.path.exists(path), f\"âŒ Missing file: {path}\"\n",
    "\n",
    "    idx = faiss.read_index(path)\n",
    "\n",
    "    # Sanity checks\n",
    "    assert idx.d == d, \"âŒ Dimension mismatch\"\n",
    "    assert type(idx) == type(base_index), \"âŒ Index type mismatch\"\n",
    "\n",
    "    # ðŸ”¥ Correct FAISS merge\n",
    "    base_index.add(idx.reconstruct_n(0, idx.ntotal))\n",
    "\n",
    "    print(f\"Appended {idx.ntotal} vectors from {path}\")\n",
    "\n",
    "# ============================\n",
    "#  SAVE\n",
    "# ============================\n",
    "faiss.write_index(base_index, OUT_INDEX)\n",
    "\n",
    "print(\"=================================\")\n",
    "print(\"âœ… Final index size:\", base_index.ntotal)\n",
    "print(\"ðŸ’¾ Saved combined index â†’\", OUT_INDEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fecf511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vectors: 13471\n",
      "Meta rows: 13471\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "FAISS_INDEX_PATH = r\"D:\\food_recommender\\embeddings\\faiss_all_images.index\"\n",
    "META_PATH = r\"D:\\food_recommender\\embeddings\\meta_clean_original_paths.pkl\"\n",
    "\n",
    "# ============================\n",
    "# LOAD\n",
    "# ============================\n",
    "index = faiss.read_index(FAISS_INDEX_PATH)\n",
    "\n",
    "with open(META_PATH, \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "print(\"FAISS vectors:\", index.ntotal)\n",
    "print(\"Meta rows:\", len(meta[\"image_path\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2be2fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Size check passed\n"
     ]
    }
   ],
   "source": [
    "assert index.ntotal == len(meta[\"image_path\"]), \\\n",
    "    \"âŒ ALIGNMENT ERROR: FAISS index and meta size mismatch\"\n",
    "\n",
    "print(\"âœ… Size check passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3e9831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Passed 50 self-retrieval checks\n"
     ]
    }
   ],
   "source": [
    "def verify_alignment(index, num_checks=50):\n",
    "    dim = index.d\n",
    "\n",
    "    for i in np.random.choice(index.ntotal, size=num_checks, replace=False):\n",
    "        i = int(i)\n",
    "        vec = index.reconstruct(i).reshape(1, dim)\n",
    "        _, I = index.search(vec, k=1)\n",
    "\n",
    "        if I[0][0] != i:\n",
    "            raise RuntimeError(f\"âŒ Vector mismatch at index {i}\")\n",
    "\n",
    "    print(f\"âœ… Passed {num_checks} self-retrieval checks\")\n",
    "\n",
    "verify_alignment(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca3529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
